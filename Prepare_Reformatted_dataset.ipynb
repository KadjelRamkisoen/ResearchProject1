{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.data import LoadData\n",
    "import torch\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_original_reformatted_dataset(dataset):\n",
    "    for i,graph in enumerate(dataset.train):\n",
    "        new_features = torch.zeros((graph[0].number_of_nodes(),28))\n",
    "        for j in range(graph[0].number_of_nodes()): \n",
    "            new_feature = torch.zeros(28)\n",
    "            print(i, '\\n', graph[0].ndata['feat'])\n",
    "            atom_type = int(graph[0].ndata['feat'][j].item())\n",
    "            print('atom_type = ',atom_type)\n",
    "            new_feature[atom_type] = 1\n",
    "#             new_feature[28] = 1\n",
    "            new_features[j] = new_feature\n",
    "        graph[0].ndata['feat'] = new_features     \n",
    "    for i,graph in enumerate(dataset.test):\n",
    "        new_features = torch.zeros((graph[0].number_of_nodes(),28))\n",
    "        for j in range(graph[0].number_of_nodes()): \n",
    "            new_feature = torch.zeros(28)\n",
    "            atom_type = int(graph[0].ndata['feat'][j].item())\n",
    "            new_feature[atom_type] = 1\n",
    "#             new_feature[28] = 1\n",
    "            new_features[j] = new_feature\n",
    "        graph[0].ndata['feat'] = new_features\n",
    "    for i,graph in enumerate(dataset.val):\n",
    "        new_features = torch.zeros((graph[0].number_of_nodes(),28))\n",
    "        for j in range(graph[0].number_of_nodes()): \n",
    "            new_feature = torch.zeros(28)\n",
    "            atom_type = int(graph[0].ndata['feat'][j].item())\n",
    "            new_feature[atom_type] = 1\n",
    "#             new_feature[28] = 1\n",
    "            new_features[j] = new_feature\n",
    "        graph[0].ndata['feat'] = new_features\n",
    "    return dataset\n",
    "\n",
    "def prepare_reduced_reformatted_dataset(dataset):\n",
    "    for i,graph in enumerate(dataset.train):\n",
    "#         new_features = torch.zeros((graph[0].number_of_nodes(),29))\n",
    "        new_features = torch.zeros((graph[0].number_of_nodes(),28))\n",
    "        weight_features = torch.zeros(graph[0].number_of_nodes(),1)\n",
    "#         weight_features = torch.zeros((graph[0].number_of_nodes(),28))\n",
    "        for j in range(graph[0].number_of_nodes()): \n",
    "#             new_feature = torch.zeros(29)\n",
    "#             weight_feature = torch.zeros(28)\n",
    "            new_feature = torch.zeros(28)\n",
    "            atom_type = int(graph[0].ndata['feat'][j][0].item())\n",
    "            new_feature[atom_type] = 1\n",
    "            weight_feature =  graph[0].ndata['feat'][j][1]\n",
    "#             weight_feature[atom_type] = graph[0].ndata['feat'][j][1]\n",
    "#             new_feature[28] = graph[0].ndata['feat'][j][1]\n",
    "            new_features[j] = new_feature\n",
    "            weight_features[j]= weight_feature\n",
    "        graph[0].ndata['feat'] = new_features\n",
    "        graph[0].ndata['weight'] = weight_features\n",
    "        graph[0].edata['feat'] = graph[0].edata['feat'].to(torch.float32)\n",
    "    for i,graph in enumerate(dataset.test):\n",
    "#         new_features = torch.zeros((graph[0].number_of_nodes(),29))\n",
    "        new_features = torch.zeros((graph[0].number_of_nodes(),28))\n",
    "#         weight_features = torch.zeros((graph[0].number_of_nodes(),28))\n",
    "        weight_features = torch.zeros(graph[0].number_of_nodes(),1)\n",
    "        for j in range(graph[0].number_of_nodes()): \n",
    "#             new_feature = torch.zeros(29)\n",
    "            new_feature = torch.zeros(28)\n",
    "#             weight_feature = torch.zeros(28)\n",
    "            atom_type = int(graph[0].ndata['feat'][j][0].item())\n",
    "            new_feature[atom_type] = 1\n",
    "            weight_feature =  graph[0].ndata['feat'][j][1]\n",
    "#             weight_feature[atom_type] = graph[0].ndata['feat'][j][1]\n",
    "#             new_feature[28] = graph[0].ndata['feat'][j][1]\n",
    "            new_features[j] = new_feature\n",
    "            weight_features[j]= weight_feature\n",
    "        graph[0].ndata['feat'] = new_features\n",
    "        graph[0].ndata['weight'] = weight_features\n",
    "        graph[0].edata['feat'] = graph[0].edata['feat'].to(torch.float32)\n",
    "    for i,graph in enumerate(dataset.val):\n",
    "#         new_features = torch.zeros((graph[0].number_of_nodes(),29))\n",
    "        new_features = torch.zeros((graph[0].number_of_nodes(),28))\n",
    "#         weight_features = torch.zeros((graph[0].number_of_nodes(),28))\n",
    "        weight_features = torch.zeros(graph[0].number_of_nodes(),1)\n",
    "        for j in range(graph[0].number_of_nodes()): \n",
    "#             new_feature = torch.zeros(29)\n",
    "#             weight_feature = torch.zeros(28)\n",
    "            new_feature = torch.zeros(28)\n",
    "            atom_type = int(graph[0].ndata['feat'][j][0].item())\n",
    "            new_feature[atom_type] = 1\n",
    "            weight_feature =  graph[0].ndata['feat'][j][1]\n",
    "#             weight_feature[atom_type] = graph[0].ndata['feat'][j][1]\n",
    "#             new_feature[28] = graph[0].ndata['feat'][j][1]\n",
    "            new_features[j] = new_feature\n",
    "            weight_features[j]= weight_feature\n",
    "        graph[0].ndata['feat'] = new_features\n",
    "        graph[0].ndata['weight'] = weight_features\n",
    "        graph[0].edata['feat'] = graph[0].edata['feat'].to(torch.float32)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LoadData(\"toy_example_original_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = prepare_reduced_reformatted_dataset(dataset)\n",
    "dataset = prepare_original_reformatted_dataset(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_atom_type = dataset.num_atom_type\n",
    "num_bond_type = dataset.num_bond_type\n",
    "    \n",
    "with open('data/molecules/toy_example_original_reformatted.pkl', 'wb') as f:\n",
    "    pickle.dump([dataset.train, dataset.val, dataset.test, num_atom_type, num_bond_type], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_atom_type = dataset.num_atom_type\n",
    "num_bond_type = dataset.num_bond_type\n",
    "    \n",
    "with open('data/molecules/ZINC_original_b.pkl', 'wb') as f:\n",
    "    pickle.dump([dataset.train, dataset.val, dataset.test, num_atom_type, num_bond_type], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
